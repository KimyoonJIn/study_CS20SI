{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fde1419da90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde17d96d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "sess = tf.InteractiveSession()\n",
    "image = np.array([[[[1],[2],[3]],[[4],[5],[6]],[[7],[8],[9]]]], dtype = np.float32)\n",
    "print(image.shape)\n",
    "plt.imshow(image.reshape(3,3), cmap='Greys') #시각화\n",
    "#1 => n개의 이미지#\n",
    "# 3*3 size\n",
    "#1 color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 1)\n",
      "conv2d_img.shape (1, 3, 3, 1)\n",
      "[[ 12.  16.   9.]\n",
      " [ 24.  28.  15.]\n",
      " [ 15.  17.   9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIEAAACFCAYAAAB8MZtGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABDVJREFUeJzt3c+LVXUch/Hn3cxVxASFWsQoXQMJ3CU6myCklbVxq4tW\nwayEgjb+Fe1mIyQhRBLUwoUgLpIIIpykwB8YkxAqQWWI7UT4tHAWN4ruEe/5nmvzvGBg7p3LuR+G\nZ879Mfd7TqoKbW7PDT2AhmcEMgIZgTACYQTCCIQRCCMQsNjLRhcXazQa9bHpzrZv3z7o/QPcu3dv\n6BGoqky7TS8RjEYjxuNxH5vubHl5edD7Bzhz5szQI3Tiw4GMQEYgjEAYgTACYQTCCIQRCCMQRiA6\nRpDkSJKbSdaTnOx7KLU1NYIkC8Aq8BawHzieZH/fg6mdLnuCZWC9qm5V1UPgLHC037HUUpcIloDb\nE5fvbFyn/4mZfZ4gyQqwArC42MvHFNSTLnuCu8Ceicu7N677m6o6VVUHq+qgETxbukRwGdiXZG+S\nLcAx4Fy/Y6mlqX+yVfUoyQngArAAnK6qa71PpmY67ber6jxwvudZNBDfMZQRyAiEEQgjEEYgjEAY\ngTACYQTCCERPxycYj8eDr80/dOjQoPcP8ODBg0Hv/9KlS51u555ARiAjEEYgjEAYgTACYQTCCIQR\nCCMQRiC6HZ/gdJJfk1xtMZDa67In+Bg40vMcGtDUCKrqK+CPBrNoID4n0OwiSLKSZC3J2v3792e1\nWTUwswgmD1Kxc+fOWW1WDfhwoE4vET8FvgFeTXInybv9j6WWuhyp5HiLQTQcHw5kBDICYQTCCIQR\nCCMQRiCMQBiBMAIBqaqZb3TXrl11+PDhmW/3SSwtDX9yltXV1aFHoKoy7TbuCWQEMgJhBMIIhBEI\nIxBGIIxAGIEwAmEEotsKpD1JvkxyPcm1JO+1GEztdDnU/SPgg6q6kmQH8F2Si1V1vefZ1EiXg1T8\nUlVXNr7/E7gBDP9/Ws3ME530IskYeA349l9+tgKsAGzbtm0Go6mVzk8MkzwPfA68X1X/OKXH5PEJ\ntm7dOssZ1bNOESQZ8TiAT6rqi35HUmtdXh0E+Ai4UVUf9j+SWuuyJ3gdeAd4M8n3G19v9zyXGupy\nkIqvgakfVtSzy3cMZQQyAmEEwgiEEQgjEEYgjEAYgTAC0dNBKpL8Bvz8FJt4Afh9RuNs5hlerqoX\np92olwieVpK1qjroDG1m8OFARqD5jeDU0AOwiWaYy+cEamte9wRqaK4iSHIkyc0k60lODjTDoOeG\nHmTZX1XNxRewAPwEvAJsAX4A9g8wxxvAAeDqQL+Hl4ADG9/vAH7s+/cwT3uCZWC9qm5V1UPgLHC0\n9RA18Lmha4Blf/MUwRJwe+LyHTb5msf/WvY3S/MUgSZMW/Y3S/MUwV1gz8Tl3RvXbTqtl/3NUwSX\ngX1J9ibZAhwDzg08U3NDLPubmwiq6hFwArjA4ydDn1XVtdZzzMG5oZsv+/MdQ83PnkDDMQIZgYxA\nGIEwAmEEwggE/AVpzG3pSuJVEAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde1414ebe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"image.shape\", image.shape)\n",
    "weight = tf.constant([[[[1.]],[[1.]]],[[[1.]],[[1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1,1,1,1],padding = 'SAME') #1*1 stride줌 #same을 했기때문에 input과 같은 사이즈나옴\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "#시각화하기위한코드\n",
    "conv2d_img = np.swapaxes(conv2d_img,0,3) #transposing 2D array\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,3,i+1), plt.imshow(one_img.reshape(3,3), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 3)\n",
      "conv2d_img.shape (1, 3, 3, 3)\n",
      "[[ 12.  16.   9.]\n",
      " [ 24.  28.  15.]\n",
      " [ 15.  17.   9.]]\n",
      "[[ 120.  160.   90.]\n",
      " [ 240.  280.  150.]\n",
      " [ 150.  170.   90.]]\n",
      "[[-12. -16.  -9.]\n",
      " [-24. -28. -15.]\n",
      " [-15. -17.  -9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAACFCAYAAAB7VhJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNwAkQ3EDQDIUNwAkQ3EDQDIUNwAk828FNQf8XgjbqwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde4cb822b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"image.shape\", image.shape)\n",
    "weight = tf.constant([[[[1.,10,-1.]],[[1.,10.,-1]]],[[[1.,10.,-1.]],[[1.,10.,-1.]]]])\n",
    "print(\"weight.shape\", weight.shape) #마지막 숫자 3은 필터의 갯수==나올 이미지의 갯수\n",
    "#필터를 몇장을 쓰는가에 따라 하나의 이미지에 대하여 여러 이미지가 나옴.\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1,1,1,1],padding = 'SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "#시각화 하기 위한 코드\n",
    "conv2d_img = np.swapaxes(conv2d_img,0,3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,3,i+1), plt.imshow(one_img.reshape(3,3), cmap= 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n",
      "[[[[ 4.]\n",
      "   [ 3.]]\n",
      "\n",
      "  [[ 2.]\n",
      "   [ 1.]]]]\n"
     ]
    }
   ],
   "source": [
    "#max pooling_어떤 데이터를 서브 샘플링한다.\n",
    "%matplotlib inline\n",
    "image = np.array([[[[4],[3]],[[2],[1]]]],dtype = np.float32)\n",
    "pool = tf.nn.max_pool(image, ksize= [1,2,2,1], strides = [1,1,1,1], padding = 'SAME') \n",
    "                 #필터사이즈 #max_pool이 CNN과 잘 동작함\n",
    "print(pool.shape)\n",
    "print(pool.eval())\n",
    "#최댓값 뽑아내는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 1)\n",
      "[[[[ 4.]]]]\n"
     ]
    }
   ],
   "source": [
    "#max pooling2\n",
    "%matplotlib inline\n",
    "image = np.array([[[[4],[3]],[[2],[1]]]],dtype = np.float32)\n",
    "pool = tf.nn.max_pool(image, ksize= [1,2,2,1], strides = [1,1,1,1], padding = 'VALID')\n",
    "print(pool.shape)\n",
    "print(pool.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#실전 이미지에 넣기\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
    "#데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fddbcd1a358>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIn/HDR9CLRAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde486ed2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[5].reshape(28,28)\n",
    "#가장 첫번째에 있는 거 불러와서 쉐잎을 28*28로 잡\n",
    "plt.imshow(img, cmap = 'gray') #출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_2:0\", shape=(1, 14, 14, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABcCAYAAAB+6068AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fddbccc57b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "img = img.reshape(-1,28,28,1) #28*28의 한 색깔, n개의 이미지일 때는 -1=(컴퓨터에게 알아서 계산해~라는 reshape의 방법)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 5], stddev=0.01)) #칼라에 신경써야함.(1) (3*3은 필터의 사이즈) (5개의 필터사용)\n",
    "conv2d = tf.nn.conv2d(img, W1, strides=[1, 2, 2, 1], padding='SAME')# (2*2는 필터를 2칸씩 옮기겠다.그래서 출력이 14*14)\n",
    "print(conv2d)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "#그림 출력하기는 code\n",
    "conv2d_img = conv2d.eval()\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(14,14), cmap='gray')\n",
    "#5개의 서로다른 필터를 사용했기 때문에 서로다른 5개의 이미지가 나옴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_2:0\", shape=(1, 7, 7, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABcCAYAAABOZ1+dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACVpJREFUeJzt3V1oVHcax/Hfk06NGkTxpcGarrpSCeKqSGspiOBFi9sb\nC950EaTiG4p4IYjrTS+ElvVyxb2RtRdtKaUXpq3QWluKVK+sBusLm4ZY3fUF7BoXEQU18dkLp83Y\nmfzPmcycOfNPvh8QM+c55P/4c/Jk5syZM+buAgDEoyXvBgAA1WFwA0BkGNwAEBkGNwBEhsENAJFh\ncANAZBjcABAZBjcARIbBDQCRKWTxTc1sTLwd090t7b5Tp071jo6OLNtpCufPn7/l7jPS7FsoFLy1\ntTXrlnJ3//791Jm0tLR4S8vofzw1ODiYOhOJmfJ7qQa3ma2S9HdJz0j6p7v/rYbeRg0z+0kpM+no\n6NCRI0ca01hOjh8/rrfffnuSmfUpRSatra3q7OxsUHf56e7u/l/a+0pLS4umTJnSuOZy0t/fnzoT\nlEv81W5mz0j6h6Q/S1og6S9mtiDrxiJBJkWDg4N65513JKlXZPKb4rWA/iDuK78hk9qleU62TFKf\nu//s7g8lfSJpdbZtxYFMhpw9e1azZ8+WpIdkMuTevXuS9ID7ypCBgQGJTGqSZnDPknS15Pa14ran\nmNlmMzttZqfr1VxEEjO5fft2Dm01zs2bN/X888+XbkrMpPgDPKo9evRIkh6WbCrLpTSTsXC1zseP\nH0sJmUhjfqYE1e1VEHc/6O4vuftL9fqesSvNZOrUqXm30xRKMykUMnltPDqlmZilfr171GOmDC/N\n4L4u6YWS2x3FbRgy5jNpb2/XjRs3SjeN+Uwk6dlnn5WkcSWbxnwuxbNmyKQGaQb3D5JeNLO5ZjZO\n0luSvsi2rTiQyZDFixfrypUrkjSOTIa0tbVJ0njuK0OKz7TIpAaJz1XdfcDMtkv6Wk9O3Xnf3S9m\n3dj8+fOD9aTTyI4dOxasHzhwILGHjRs3Ju3S0Eza29uD9aTjoxMmTAjWi8ceg65evVpxe6FQ0N69\ne7V+/fr5kv6lBmWSpLu7O1hfsWJFsL53797ENXbu3DlsrXjo4z9q8H0lZOnSpcH6a6+9Fqzv2rUr\ncY3p06cPW2vGTCTpxIkTwfqCBeETX44ePZq4xtq1a6vqaTipDjK6+5eSvqzLiqOIu4d/u4wxK1eu\nlKQLHJMsc4dMypBJDUb/W7QAYJRhcANAZBjcABAZBjcARIbBDQCRYXADQGQY3AAQmaa9WERvb2+w\nPmtW2TVpnrJkyZJg/fjx49W2lLubN28G6/39/cH6hg0bgvXPPvus6p6aXdKbktatWxesL168uJ7t\nNIXiha+Gdfp0+JpOc+fOrWc7DbNw4cJgfd68ecH69u3bg/U9e/ZU3dNI8YgbACLD4AaAyDC4ASAy\nDG4AiAyDGwAiw+AGgMgwuAEgMrmcxz1+/PjEfXbv3h2sJ53HffFi+LrsxY9Pahqtra2J+zx48CBY\nP3XqVLD+6quvVtXTaLBq1apgff/+/cH6vn376tlOQyT9P7/88svBek9PT7B+9+7dqntqBjNmzAjW\nk94nkfThK6+88krVPY1Uc00vAEAiBjcARIbBDQCRYXADQGQY3AAQGQY3AESGwQ0AkcnlPO6JEycm\n7nPp0qVg/fPPPw/Wt27dGqxv2bIlsYdGSnNu+8yZM4P1e/fuBesffPBBVT3l7dq1a4n7fPTRR8H6\n5cuXg/WOjo5g/dixY4k9NFLSNdclqa+vL1g/efJksP7dd98F682WiSS99957ifskXS/73Llzwfrh\nw4eD9aTc64lH3AAQGQY3AESGwQ0AkWFwA0BkGNwAEBkGNwBEhsENAJHJ5Tzu27dvJ+7z4YcfButf\nffVVsP7pp59W1VPe7ty5k7jPmjVrgvU33ngjWN+2bVtVPeUt6RxrSerq6grWJ0+eHKz39vZW1VPe\npk2blrjPoUOHgvUzZ84E68uXLw/WJ0yYkNhDoyX9m6TkmfDmm28G60n3x02bNiX2UC+pBreZXZF0\nV9KgpAF3fynLpmJhZudFJr/3J3IpQyblyKQG1TziXunutzLrJE5kUhm5lCOTcmQyQhzjBoDIpB3c\nLulbMztjZpsr7WBmm83stJmdrl97TS91JmmO648iw+ZSmsnAwEAeveUlVSbunkdveWGmjFDaQyXL\n3f26mT0n6Rsz63H370t3cPeDkg5KkpmNiXufuy9Jm8miRYvGRCaSekK5lGbS1tZGJno6k0KhQCZF\nY3GmpJXqEbe7Xy/+/YukLknLsmwqJmRS5pFELr9DJuXIpAaJg9vM2sxs0q9fS3pd0oWsG4sFmQy5\nf/++VLxPkcsTg4ODEpk8pXg4iExqkOZQSbukLjP7df+P3f1opl1Fwsx+FJn85tatW5LUSS5Disfx\nyaTE48ePJTKpiWXxYkgjjketXr06WE/6oIV6cHdLu++iRYv8yJEjWbbTFObMmXMm7Tm5bW1t3tnZ\nWdN6SR/KkfRmkkZ8KEB3d3fqTAqFgk+ZMiXrlnLX39+fOhOpPjPl3XffDdYnTZoUrO/YsaPWFhKl\nnSmcDggAkWFwA0BkGNwAEBkGNwBEhsENAJFhcANAZBjcABCZrM7j/q+kf5dsmi6p2S/fWG2Ps919\nRtqdx0gmUhW5kEm5CpmMdM1G4+enXGaZZDK4yxZ5ctWzpr5QeqN7JJP81xuJPHokl/zXG4kse+RQ\nCQBEhsENAJFp1OA+2KB1atHoHskk//VGIo8eySX/9UYisx4bcowbAFA/HCoBgMhkOrjNbJWZ/WRm\nfWb21yzXqoWZXTGz82Z2NuvPtyOTYddr+lzIpByZVJZ5Lu6eyR9Jz0i6JOmPksZJ+lHSgqzWq7HX\nK5KmN2AdMok4FzIhk2bJJctH3Msk9bn7z+7+UNInksKffjD6kUll5FKOTMqRSVGWg3uWpKslt68V\ntzUjl/StmZ0xs80ZrkMmlcWSC5mUI5PKMs0lzWdOjgXL3f26mT0n6Rsz63H37/NuKmdkUo5MypFJ\nZZnmkuUj7uuSXii53VHc1nTc/Xrx718kdenJU7IskEllUeRCJuXIpLKsc8lycP8g6UUzm2tm4yS9\nJemLDNcbETNrM7NJv34t6XVJFzJajkwqa/pcyKQcmVTWiFwyO1Ti7gNmtl3S13ryavD77n4xq/Vq\n0C6py8ykJ3l87O5Hs1iITCqLJBcyKUcmlWWeC++cBIDI8M5JAIgMgxsAIsPgBoDIMLgBIDIMbgCI\nDIMbACLD4AaAyDC4ASAy/wdnaEtsgzbovgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde140eb898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#max pooling\n",
    "pool = tf.nn.max_pool(conv2d, ksize=[1, 2, 2, 1], strides=[\n",
    "                        1, 2, 2, 1], padding='SAME')\n",
    "#입력 이미지 14*14인데 또 필터가 두탄씩 움직이니까 7*7로 또 줄어듦.\n",
    "print(pool)\n",
    "#실행코드\n",
    "sess.run(tf.global_variables_initializer())\n",
    "pool_img = pool.eval()\n",
    "#출력 code\n",
    "pool_img = np.swapaxes(pool_img, 0, 3)\n",
    "for i, one_img in enumerate(pool_img):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(7, 7), cmap='gray')\n",
    "\n",
    "#7*7의 이미지가 나옴. 이미지가 서브 샘플링되어서 해상도가 떨어져있음. max pooling을 이용해서 간단한 서브 샘플링을 해봄."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.478379004\n",
      "Epoch: 0002 cost = 0.107837441\n",
      "Epoch: 0003 cost = 0.078062812\n",
      "Epoch: 0004 cost = 0.064202867\n",
      "Epoch: 0005 cost = 0.053259693\n",
      "Epoch: 0006 cost = 0.049641101\n",
      "Epoch: 0007 cost = 0.043886360\n",
      "Epoch: 0008 cost = 0.039404330\n",
      "Epoch: 0009 cost = 0.037726444\n",
      "Epoch: 0010 cost = 0.035387208\n",
      "Epoch: 0011 cost = 0.032274738\n",
      "Epoch: 0012 cost = 0.033030399\n",
      "Epoch: 0013 cost = 0.029083194\n",
      "Epoch: 0014 cost = 0.027826021\n",
      "Epoch: 0015 cost = 0.027642632\n",
      "Learning Finished!\n",
      "Accuracy: 0.9939\n",
      "Label:  [5]\n",
      "Prediction:  [5]\n"
     ]
    }
   ],
   "source": [
    "# Lab 11 MNIST and Deep learning CNN\n",
    "import tensorflow as tf\n",
    "import random\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True) #vector표현가능하게one_hot=True\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# dropout (keep_prob) rate  0.7~0.5 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "#Conv layer1\n",
    "#input의 이미지를 우리가 원하는대로 만들어야\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784]) #784인 이유는 MNIST가 784개이기 때문\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1(칼라) (black/white) #이미지로 넣기 위해서 #x_img가 입력이 될 것.\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#첫번째 conv layer1\n",
    "# L1 ImgIn shape=(?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01)) #3*3size의 필터 #1은 칼라 #32 필터\n",
    "#    Conv     -> (?, 28, 28, 32)\n",
    "#    Pool     -> (?, 14, 14, 32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "#필터 2*2 # stride 2*2 # 28*28->14*14\n",
    "\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "'''\n",
    "#conv layer2\n",
    "# L2 ImgIn shape=(?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01)) #32는 필터의 갯수와 같아야함. 64개의 필터를 쓸 것\n",
    "#    Conv      ->(?, 14, 14, 64)\n",
    "#    Pool      ->(?, 7, 7, 64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "Tensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "'''\n",
    "\n",
    "#conv layer3\n",
    "# L3 ImgIn shape=(?, 7, 7, 64)\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "#    Conv      ->(?, 7, 7, 128)\n",
    "#    Pool      ->(?, 4, 4, 128)\n",
    "#    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                    1, 2, 2, 1], padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "\n",
    "#입체적인 모양을 쭉 펼쳐야됨. 128*4*4만크므이 길이를 갖는게 n개 있게됨.\n",
    "L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "'''\n",
    "Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "Tensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)\n",
    "'''\n",
    "#FC를 2번하겠다.그럼 정확도가 높아짐.\n",
    "#Conv layer4\n",
    "# L4 FC 4x4x128 inputs -> 625 outputs\n",
    "#벡터 입력의 값 = 128*4*4 출력의 값 625개\n",
    "W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "#bias를 출력의 값과 똑같게 줌 (625)\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "#곱하고 더한다.\n",
    "L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "#학습할때는 dropout을 0.5나 0.7로\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\n",
    "Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\n",
    "'''\n",
    "#Fully connecter(fc,dense) layer\n",
    "# L5 Final FC 625 inputs 입력받아서 -> 10 outputs\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L4, W5) + b5\n",
    "'''\n",
    "Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
    "'''\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "#Training and Evaluation\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습시키기\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# 학습이 잘 되었는지 평가하기\n",
    "\n",
    "# if you have a OOM error, please refer to lab-11-X-mnist_deep_cnn_low_memory.py\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "#test할 때는 반드시 dropout을 1로\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
    "\n",
    "# plt.imshow(mnist.test.images[r:r + 1].\n",
    "#           reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "# plt.show(\n",
    "#cost가 떨어지면서99프로까지 정확성을 얻을 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Learning Started!\n",
      "Epoch: 0001 cost = 0.404052137\n",
      "Epoch: 0002 cost = 0.090525415\n",
      "Epoch: 0003 cost = 0.068485891\n",
      "Epoch: 0004 cost = 0.058093703\n",
      "Epoch: 0005 cost = 0.050667376\n",
      "Epoch: 0006 cost = 0.042372070\n",
      "Epoch: 0007 cost = 0.040836713\n",
      "Epoch: 0008 cost = 0.038622323\n",
      "Epoch: 0009 cost = 0.035570359\n",
      "Epoch: 0010 cost = 0.032131624\n",
      "Epoch: 0011 cost = 0.031765728\n",
      "Epoch: 0012 cost = 0.032215357\n",
      "Epoch: 0013 cost = 0.027459460\n",
      "Epoch: 0014 cost = 0.027606058\n",
      "Epoch: 0015 cost = 0.026013258\n",
      "Learning Finished!\n",
      "Accuracy: 0.9951\n"
     ]
    }
   ],
   "source": [
    "#위의 코드는 관리하기 불편함.그래서 python의 class으로 보다 효과적으로 관리.\n",
    "# Lab 11 MNIST and Deep learning CNN\n",
    "\n",
    "import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "    #초기화\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "#네트워크를 빌드하는 건 다 넣음.\n",
    "        \n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
    "            # for testing\n",
    "            self.keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "            # input place holders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "            # img 28x28x1 (black/white)\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "            # L1 ImgIn shape=(?, 28, 28, 1)\n",
    "            W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "            #    Conv     -> (?, 28, 28, 32)\n",
    "            #    Pool     -> (?, 14, 14, 32)\n",
    "            L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L1 = tf.nn.relu(L1)\n",
    "            L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                                strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L1 = tf.nn.dropout(L1, keep_prob=self.keep_prob)\n",
    "            '''\n",
    "            Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "            Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "            Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "            Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L2 ImgIn shape=(?, 14, 14, 32)\n",
    "            W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "            #    Conv      ->(?, 14, 14, 64)\n",
    "            #    Pool      ->(?, 7, 7, 64)\n",
    "            L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L2 = tf.nn.relu(L2)\n",
    "            L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                                strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L2 = tf.nn.dropout(L2, keep_prob=self.keep_prob)\n",
    "            '''\n",
    "            Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "            Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "            Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "            Tensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L3 ImgIn shape=(?, 7, 7, 64)\n",
    "            W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "            #    Conv      ->(?, 7, 7, 128)\n",
    "            #    Pool      ->(?, 4, 4, 128)\n",
    "            #    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
    "            L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L3 = tf.nn.relu(L3)\n",
    "            L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                                1, 2, 2, 1], padding='SAME')\n",
    "            L3 = tf.nn.dropout(L3, keep_prob=self.keep_prob)\n",
    "\n",
    "            L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "            '''\n",
    "            Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "            Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "            Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "            Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "            Tensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L4 FC 4x4x128 inputs -> 625 outputs\n",
    "            W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b4 = tf.Variable(tf.random_normal([625]))\n",
    "            L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "            L4 = tf.nn.dropout(L4, keep_prob=self.keep_prob)\n",
    "            '''\n",
    "            Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\n",
    "            Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\n",
    "            '''\n",
    "\n",
    "            # L5 Final FC 625 inputs -> 10 outputs\n",
    "            W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b5 = tf.Variable(tf.random_normal([10]))\n",
    "            self.logits = tf.matmul(L4, W5) + b5\n",
    "            '''\n",
    "            Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
    "            '''\n",
    "\n",
    "        # define cost/loss & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "        correct_prediction = tf.equal(\n",
    "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#예측하는거\n",
    "    def predict(self, x_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.keep_prob: keep_prop})\n",
    "#정확도를 얻는 것\n",
    "    def get_accuracy(self, x_test, y_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.accuracy, feed_dict={self.X: x_test, self.Y: y_test, self.keep_prob: keep_prop})\n",
    "#학습하는 서\n",
    "    def train(self, x_data, y_data, keep_prop=0.7):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data, self.Y: y_data, self.keep_prob: keep_prop})\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "                                               #model1을 만듦.\n",
    "m1 = Model(sess, \"m1\")\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "                                               #session run할 필요없이 ml에 train 함수를 호출해버리면 됨.\n",
    "                                               #깔끔하게 관리가 됨.\n",
    "        c, _ = m1.train(batch_xs, batch_ys)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
